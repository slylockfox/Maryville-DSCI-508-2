{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e4cf50-50b4-4b20-966a-976b2fcf31f7",
   "metadata": {},
   "source": [
    "# DSCI-508 Project 7\n",
    "### Matt Snyder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d1b832-b8a7-4165-8af8-d05f0354c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7faba6-0074-4d90-a382-a5581e7ca98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/matt/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# To start, we need some text to play with. NLTK has many corpora and resources for you to explore natural language. \n",
    "# A one-off run of nltk.download() will get you all the resources in one go. Once you've done that you should have \n",
    "# a repository of interesting texts including stuff like Moby Dick and an Inaugural Address Corpus\n",
    "\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9b5c5c-4036-4423-a753-67d7c5810ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "print(movie_reviews.categories()) # 'pos' (positive) and 'neg' (negative)\n",
    "# print(movie_reviews.fileids()) # Lists review filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb681aee-39d8-4a78-8e61-4fa22fdb2a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/matt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e2e462-fa65-4f41-9600-ca101ec3ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "customStopWords=set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf1c95b0-046e-488e-af3e-9d317eecce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc34d2f-cbfd-4bfb-86e4-f70f12d8a3d1",
   "metadata": {},
   "source": [
    "## Create DataFrame of Positive Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80dfa44a-7cc3-4c4f-afe7-c0fb8f734772",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_fileids = movie_reviews.fileids(categories='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e69b7d91-8dad-4b9f-8887-7da309f90466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'films adapted from comic books have had plenty of success , whether they\\'re about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there\\'s never really been a comic book like from hell before . \\nfor starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid \\'80s with a 12-part series called the watchmen . \\nto say moore and campbell thoroughly researched the subject of jack the ripper would be like saying michael jackson is starting to look a little odd . \\nthe book ( or \" graphic novel , \" if you will ) is over 500 pages long and includes nearly 30 more that consist of nothing but footnotes . \\nin other words , don\\'t dismiss this film because of its source . \\nif you can get past the whole comic book thing , you might find another stumbling block in from hell\\'s directors , albert and allen hughes . \\ngetting the hughes brothers to direct this seems almost as ludicrous as casting carrot top in , well , anything , but riddle me this : who better to direct a film that\\'s set in the ghetto and features really violent street crime than the mad geniuses behind menace ii society ? \\nthe ghetto in question is , of course , whitechapel in 1888 london\\'s east end . \\nit\\'s a filthy , sooty place where the whores ( called \" unfortunates \" ) are starting to get a little nervous about this mysterious psychopath who has been carving through their profession with surgical precision . \\nwhen the first stiff turns up , copper peter godley ( robbie coltrane , the world is not enough ) calls in inspector frederick abberline ( johnny depp , blow ) to crack the case . \\nabberline , a widower , has prophetic dreams he unsuccessfully tries to quell with copious amounts of absinthe and opium . \\nupon arriving in whitechapel , he befriends an unfortunate named mary kelly ( heather graham , say it isn\\'t so ) and proceeds to investigate the horribly gruesome crimes that even the police surgeon can\\'t stomach . \\ni don\\'t think anyone needs to be briefed on jack the ripper , so i won\\'t go into the particulars here , other than to say moore and campbell have a unique and interesting theory about both the identity of the killer and the reasons he chooses to slay . \\nin the comic , they don\\'t bother cloaking the identity of the ripper , but screenwriters terry hayes ( vertical limit ) and rafael yglesias ( les mis ? rables ) do a good job of keeping him hidden from viewers until the very end . \\nit\\'s funny to watch the locals blindly point the finger of blame at jews and indians because , after all , an englishman could never be capable of committing such ghastly acts . \\nand from hell\\'s ending had me whistling the stonecutters song from the simpsons for days ( \" who holds back the electric car/who made steve guttenberg a star ? \" ) . \\ndon\\'t worry - it\\'ll all make sense when you see it . \\nnow onto from hell\\'s appearance : it\\'s certainly dark and bleak enough , and it\\'s surprising to see how much more it looks like a tim burton film than planet of the apes did ( at times , it seems like sleepy hollow 2 ) . \\nthe print i saw wasn\\'t completely finished ( both color and music had not been finalized , so no comments about marilyn manson ) , but cinematographer peter deming ( don\\'t say a word ) ably captures the dreariness of victorian-era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks , even though the violence in the film pales in comparison to that in the black-and-white comic . \\noscar winner martin childs\\' ( shakespeare in love ) production design turns the original prague surroundings into one creepy place . \\neven the acting in from hell is solid , with the dreamy depp turning in a typically strong performance and deftly handling a british accent . \\nians holm ( joe gould\\'s secret ) and richardson ( 102 dalmatians ) log in great supporting roles , but the big surprise here is graham . \\ni cringed the first time she opened her mouth , imagining her attempt at an irish accent , but it actually wasn\\'t half bad . \\nthe film , however , is all good . \\n2 : 00 - r for strong violence/gore , sexuality , language and drug content \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.raw(fileids=pos_fileids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d25864c-a32c-446e-8c38-865642d9432b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>[every, movie, comes, along, suspect, studio, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you've got mail works alot better than it dese...</td>\n",
       "      <td>[got, mail, works, alot, better, deserves, ord...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" jaws \" is a rare film that grabs your atten...</td>\n",
       "      <td>[jaws, rare, film, grabs, attention, shows, si...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "      <td>[moviemaking, lot, like, general, manager, nfl...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  every now and then a movie comes along from a ...   \n",
       "2  you've got mail works alot better than it dese...   \n",
       "3   \" jaws \" is a rare film that grabs your atten...   \n",
       "4  moviemaking is a lot like being the general ma...   \n",
       "\n",
       "                                               words vector  \n",
       "0  [films, adapted, comic, books, plenty, success...     []  \n",
       "1  [every, movie, comes, along, suspect, studio, ...     []  \n",
       "2  [got, mail, works, alot, better, deserves, ord...     []  \n",
       "3  [jaws, rare, film, grabs, attention, shows, si...     []  \n",
       "4  [moviemaking, lot, like, general, manager, nfl...     []  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataframe with two columns: text of the movie review, tokenized words (unordered) minus stop words\n",
    "# also a column for the tf/idf vector\n",
    "df_dict = {'text':[], 'words':[], 'vector':[]}\n",
    "for id in pos_fileids:\n",
    "    df_dict['text'].append (movie_reviews.raw(fileids=id))\n",
    "    df_dict['words'].append (list(movie_reviews.words(fileids=id)))\n",
    "    df_dict['vector'].append ([])\n",
    "df = pd.DataFrame(df_dict)\n",
    "# remove stopwords and punctuation\n",
    "df['words'] = df['words'].apply(lambda x: [term for term in x if term not in customStopWords])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930818d-ed41-4f97-af11-cbe46cde9648",
   "metadata": {},
   "source": [
    "## Compute Vectors using TF/IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2da54a-4d99-461b-bcca-b7a6c2f24798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30236\n"
     ]
    }
   ],
   "source": [
    "# master vector of union of all words in reviews\n",
    "master_set = set(df.loc[0, 'words'])\n",
    "for i in range(1, len(df)):\n",
    "    master_set.update(df.loc[i, 'words']) # accumulate union of words in set\n",
    "master_array = np.array(list(master_set)) # convert set to array\n",
    "print (len(master_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abb8a339-030a-40ca-991a-7ba0ab6a4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tf/idf for each review\n",
    "\n",
    "# first pass, assemble vectors with just term freq\n",
    "tf_vectors = []\n",
    "for i in range(0, len(df)):\n",
    "    fdist = FreqDist(df.loc[i, 'words'])\n",
    "    vector = np.array([fdist[word] for word in master_array])\n",
    "    tf_vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d67b83ba-1fa5-4732-8de2-ee716ab4ac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  2 15  1 18  1  1  7  2  6  1  1  6  1  1 23  2  8  2  1]\n"
     ]
    }
   ],
   "source": [
    "# using vectors of tf, compute document counts of these same words\n",
    "\n",
    "# convert non-zero term counts into 1's\n",
    "def zero_or_not(x):\n",
    "    return 1 if x > 0 else 0\n",
    "zero_or_not_vectorized = np.vectorize(zero_or_not)\n",
    "doc_count_vectors = [zero_or_not_vectorized(v) for v in tf_vectors]\n",
    "\n",
    "# convert array list to matrix and sum the 1's \n",
    "doc_count_matrix = np.stack(doc_count_vectors)\n",
    "doc_counts_per_word = np.sum(doc_count_matrix, axis=0)\n",
    "print (doc_counts_per_word[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "791c718c-2cfd-40a1-8526-63160ac5218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.90975328 6.90975328 6.92264389 6.90875478 6.9255952  6.90875478\n",
      " 6.90875478 6.91473089 6.90975328 6.91373735 6.90875478 6.90875478\n",
      " 6.91373735 6.90875478 6.90875478 6.93049477 6.90975328 6.91572345\n",
      " 6.90975328 6.90875478]\n"
     ]
    }
   ],
   "source": [
    "# compute idf = inverse document frequency\n",
    "# = log of the number of documents divided by the log of one plus the number of documents containing that word\n",
    "def idf(doc_count:int, total_docs:int):\n",
    "    return math.log( total_docs / 1+doc_count )\n",
    "idf_vectorized = np.vectorize(idf)\n",
    "total_docs = len(df)\n",
    "idf_per_word = idf_vectorized(doc_counts_per_word, total_docs)\n",
    "print (idf_per_word[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75691b6a-b6ad-4b82-a70a-515681313bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         6.95749737 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         6.90975328 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# product of tf vectors and idf vector gives final tf/idf vectors\n",
    "tf_idf_vectors = [v * idf_per_word for v in tf_vectors]\n",
    "print (tf_idf_vectors[0][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f8a9573-eda5-4fa9-bb95-766f3a36f166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         6.95749737 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         6.90975328 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>[every, movie, comes, along, suspect, studio, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you've got mail works alot better than it dese...</td>\n",
       "      <td>[got, mail, works, alot, better, deserves, ord...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" jaws \" is a rare film that grabs your atten...</td>\n",
       "      <td>[jaws, rare, film, grabs, attention, shows, si...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "      <td>[moviemaking, lot, like, general, manager, nfl...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  every now and then a movie comes along from a ...   \n",
       "2  you've got mail works alot better than it dese...   \n",
       "3   \" jaws \" is a rare film that grabs your atten...   \n",
       "4  moviemaking is a lot like being the general ma...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [films, adapted, comic, books, plenty, success...   \n",
       "1  [every, movie, comes, along, suspect, studio, ...   \n",
       "2  [got, mail, works, alot, better, deserves, ord...   \n",
       "3  [jaws, rare, film, grabs, attention, shows, si...   \n",
       "4  [moviemaking, lot, like, general, manager, nfl...   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add tf/idf vector column to dataframe\n",
    "df['vector'] = tf_idf_vectors\n",
    "print (df.loc[0, 'vector'][0:100])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cdc901-1339-469e-b8fb-932f25f24543",
   "metadata": {},
   "source": [
    "## Test Vectors With Cluster Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "511edf92-ddfd-4207-bc12-6a682ae0952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30236)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KMeans</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=100)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try making a cluster model with large number of clusters\n",
    "X = np.stack(df['vector'].values)\n",
    "print (X.shape)\n",
    "model = KMeans(n_clusters=100)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f76da106-759e-41f5-817a-44eb4673ab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>vector</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>[every, movie, comes, along, suspect, studio, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you've got mail works alot better than it dese...</td>\n",
       "      <td>[got, mail, works, alot, better, deserves, ord...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" jaws \" is a rare film that grabs your atten...</td>\n",
       "      <td>[jaws, rare, film, grabs, attention, shows, si...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "      <td>[moviemaking, lot, like, general, manager, nfl...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  every now and then a movie comes along from a ...   \n",
       "2  you've got mail works alot better than it dese...   \n",
       "3   \" jaws \" is a rare film that grabs your atten...   \n",
       "4  moviemaking is a lot like being the general ma...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [films, adapted, comic, books, plenty, success...   \n",
       "1  [every, movie, comes, along, suspect, studio, ...   \n",
       "2  [got, mail, works, alot, better, deserves, ord...   \n",
       "3  [jaws, rare, film, grabs, attention, shows, si...   \n",
       "4  [moviemaking, lot, like, general, manager, nfl...   \n",
       "\n",
       "                                              vector  cluster  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       68  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       68  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       22  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       74  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...       31  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add cluster labels onto dataframe\n",
    "clusters = model.labels_ # labels of all the X data; no need to run predict to get it, since it's saved in model\n",
    "df['cluster'] = clusters\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f5c7a7-7292-4bf7-908e-566e6d739074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 9, 10, 23, 33, 51, 53, 80, 89]\n"
     ]
    }
   ],
   "source": [
    "# find small clusters, i.e. those containing 2 reviews\n",
    "hist_counts, bin_edges = np.histogram(clusters, bins=100)\n",
    "clusters_with_two_reviews = [i for i, count in enumerate(hist_counts) if count == 2]\n",
    "print (clusters_with_two_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c95f47d-90b1-4c4b-bea8-a6da3b5d7089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i think the first thing this reviewer should mention is wether or not i am a fan of the x-files . \n",
      "first , let me assure you that no prior experience with the series is required to fully enjoy this movie . \n",
      "the producers are not stupid , making a movie just for fans of the series is not profitable . \n",
      "you have to reach for a larger audience . \n",
      "therefore , the movie is quite user-friendly . \n",
      "altough , non-fans will only fail to understand certain emotions behind the looks many characters exchange \n",
      "\n",
      "i think the first thing this reviewer should mention is wether or not i am a fan of the x-files . \n",
      "first , let me assure you that no prior experience with the series is required to fully enjoy this movie . \n",
      "the producers are not stupid , making a movie just for fans of the series is not profitable . \n",
      "you have to reach for a larger audience . \n",
      "therefore , the movie is quite user-friendly . \n",
      "altough , non-fans will only fail to understand certain emotions behind the looks many characters exchange \n",
      "\n",
      "----------------------------------------------\n",
      "i know that \" funnest \" isn't a word . \n",
      " \" fun \" is a noun , and therefore cannot be conjugated like an adjective . \n",
      "but that's the word that came to me right after viewing \" chicken run . \" \n",
      "no wonder : this is the kind of movie that reduces you to childish expressions , like \" that was the funnest movie i've ever seen ! \" \n",
      "so to hell with webster's -- \" chicken run \" is one of the funnest movies i've seen in a while . \n",
      "i can't remember the last time i've seen anything funner . \n",
      "the chickens at\n",
      "\n",
      "i know that \" funnest \" isn't a word . \n",
      " \" fun \" is a noun , and therefore cannot be conjugated like an adjective . \n",
      "but that's the word that came to me right after viewing \" chicken run . \" \n",
      "no wonder : this is the kind of movie that reduces you to childish expressions , like \" that was the funnest movie i've ever seen ! \" \n",
      "so to hell with webster's -- \" chicken run \" is one of the funnest movies i've seen in a while . \n",
      "i can't remember the last time i've seen anything funner . \n",
      "the chickens at\n",
      "\n",
      "----------------------------------------------\n",
      "ultra low budget but extremely inventive horror film about a group of friends vacationing in a cabin who accidentally awaken an evil force in the woods via the necronomicon , the book of the dead . \n",
      "bruce campbell stars as ash , who eventually becomes the sole survivor and has to battle both the demons from the woods , and his friends who have become demons ( including his own girlfriend ) . \n",
      "the results shown on screen are amazing considering the film's tiny budget , constant location changes ,\n",
      "\n",
      " \" love is the devil \" is a challenging film , munundating its audience with wild imagery and a plot structure that disallows a plot , perhaps in an attempt to get us to know the artist's psyche rather than the artist's lifeline . \n",
      "watching it , i was enthralled with the look of the film , the way the director shot everything like it was looking through a bizarre , personalized filter . \n",
      "everything looks like it is not how life looks like but how painter francis bacon , the film's subject , look\n",
      "\n",
      "----------------------------------------------\n",
      "with the success of the surprise hit alien , directed by ridley scott , a sequel was inevitable . \n",
      "in fact , after watching the first film , a sequel was wanted , particularly by this reviewer . \n",
      "handing over the director's chair to recent box office gem james cameron , who had only made two films previous to this one ( pirahna ii , a surprisingly dull film , and terminator , making cameron a household name ) , the alien series got a face-lift of immense proportions . \n",
      "instead of being a suspens\n",
      "\n",
      "i'm an avid fan of the \" alien \" saga , so this review is obviously a tad biased ( at least i admitted it ) . \n",
      "of course , that doesn't mean that i'm gonna be giving this a four-star review or something , because \" alien : resurrection , \" the fourth film in the cool-as-hell series is not an absolutely amazing film , much like the first two were . \n",
      "however , it's a very good film which never fails to entertain , and consists of yet another mutation in the style of the series . \n",
      "in short , i had \n",
      "\n",
      "----------------------------------------------\n",
      "i suppose an argument could be made that toy story is one of those films that didn't need a sequel . \n",
      "beloved by kids and their parents , respected equally by mainstream america and geekish movie buffs , that first movie remains a landmark of recent history , the one that burst open the possibilities of computer animation and demonstrated through wild invention and giddy chutzpah just how complacent the disney animation machine had become in cranking out fluffy razzle-dazzle entertainment full o\n",
      "\n",
      "when andy leaves for cowboy camp , his mother holds a yard sale and scrounges in his room for old toys . \n",
      "one of these toys is wheezy , a penguin with a broken squeaker . \n",
      "woody ( tom hanks ) saddles up andy's dog and rides out into the yard to rescue wheezy . \n",
      "woody succeeds in his mission , but doesn't make it back to the house before al , the unscrupulous owner of al's toy barn , recognizes woody as a rare collector's item and steals him . \n",
      "buzz lightyear ( tim allen ) leads hamm ( john ratze\n",
      "\n",
      "----------------------------------------------\n",
      "seen december 28 , 1997 at 8 : 45 p . m . at the crossgates mall cinema 18 ( guilderland , ny ) , theater #8 , with matt perreault and my sister jena for free ( matt paid using pre-paid passes ) . \n",
      "if there's ever been an exception to the perils of excessive cliches and non- stop action , the james bond films are it . \n",
      "and if there's ever been a james bond film that not only proves this , but does so by pushing it to the extreme , \" tomorrow never dies \" is it . \n",
      "opening sequences almost always \n",
      "\n",
      "the bond series is an island in the film world ; where else would we look forward to cliches , and all of the other things that occur in most of these films ? \n",
      "where else would pure escapism , a vulnerable hero , the \" talking villains , \" blatant product placement , predictable action sequences , and lots of promiscuity be hoped for instead of a significant change ? \n",
      "i don't understand it myself , but that's what the bond series is based on . \n",
      "for ( i think ) 18 films , we've mostly got the sam\n",
      "\n",
      "----------------------------------------------\n",
      "no , it is not a bad film , in fact it is so good in achieving its purpose , i actually wished for the film to end itself quickly . \n",
      "event horizon is not your run-of-the-mill sci-fi film , i'm sure many who have watched this will agree with me . \n",
      "it is not even original in that sense , and it does borrow heavily from films like alien , hellraiser and even blade runner . \n",
      "the magic of this film lies in its unorthodox setting and methodical build-up that makes it wonderfully horrifying . \n",
      "the stor\n",
      "\n",
      "no , it is not a bad film , in fact it is so good in achieving its = purpose , i actually wished for the film to end itself quickly . \n",
      "event = horizon is not your run-of-the-mill sci-fi film , i'm sure many who have = watched this will agree with me . \n",
      "it is not even original in that sense , = and it does borrow heavily from films like alien , hellraiser and even = blade runner . \n",
      "the magic of this film lies in its unorthodox setting and = methodical build-up that makes it wonderfully horrifying\n",
      "\n",
      "----------------------------------------------\n",
      "i want to correct what i wrote in a former retrospective of david lean's war picture . \n",
      "i still think that it doesn't deserve being the number 13 in the american film institute's list of the 100 greatest american movies . \n",
      "and i think that lumet's \" 12 angry men \" , wilder's \" witness for the prosecution \" and kubrick's \" paths of glory \" would have been better choices for the best picture oscar in 1958 . \n",
      "but i can't deny the importance of \" the bridge on the river kwai \" - cinematically and in\n",
      "\n",
      "i want to correct what i wrote last year in my retrospective of david lean's war picture . \n",
      "i still think that \" the bridge on the river kwai \" doesn't deserve being the number 13 in the american film institute's list of the 100 greatest american movies . \n",
      "and i think that \" 12 angry men \" , \" witness for the prosecution \" and \" paths of glory \" would have been better choices for the oscar for the best picture of 1957 . \n",
      "but i can't deny the importance of \" the bridge on the river kwai \" - cinem\n",
      "\n",
      "----------------------------------------------\n",
      "city of angels is the kind of love story that i enjoy the most : thought-provoking , moving , and completely unsentimental . \n",
      "i find it interesting that this film has been released the same day as my giant , which is a film that is undone completely by its wretched sentimentality . \n",
      "city of angels is a wonderful film , enhanced by interesting and well-rounded characters and some of the most immersive imagery of the last couple of years . \n",
      "it's a love story that takes the familiar angel themes an\n",
      "\n",
      "there is a striking scene early in \" city of angels , \" where all the angels who live unseen in our midst , gather at the beach to watch the sun rise . \n",
      "the camera moves above them , showing the endless rows of ethereal men and women , all garbed in black . \n",
      "then the camera moves in on the face of seth , an angel played by nicolas cage , and as the sun rises , he smiles and his entire face lights up . \n",
      "you see , the angels can hear music in sunrises and sunsets , but they cannot feel a human tou\n",
      "\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# show the reviews from the 2-review clusters\n",
    "for cluster in clusters_with_two_reviews:\n",
    "    sel = df.loc[:,'cluster'] == cluster\n",
    "    similar_reviews_df = df.loc[sel, :]\n",
    "    review_texts = similar_reviews_df['text'].values\n",
    "    for i in range(0, len(review_texts)):\n",
    "        print (review_texts[i][0:500])\n",
    "        print ()\n",
    "    print ('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf2b70-03a4-4da8-a45b-55cdb524f3ab",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The reviews in the 2-review clusters do indeed use similar words, and many are about the same movie, therefore TF/IDF can be used to compare two chunks of text.  And many of the results in the 2-review clusters were apparently duplicates, so this is also a useful method for finding duplicates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
